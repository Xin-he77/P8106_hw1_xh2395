---
title: "P8106_hw1_xh2395"
author: "Xin  He"
date: "2/29/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(
    fig.align = 'center',
    fig.width = 7,
    fig.asp = 0.6,
    out.width = "80%",
    message = F,
    warning = F
 )
library(caret)
library(pls)
```

## Homework 1 Description

In this exercise, we will predict solubility of compounds using their chemical structures.
The training data are in the file "solubility_train.csv" and the test data are in the file "solubility_test.csv". Among the 228 predictors, 208 are binary variables that indicate the presence or absence of a particular chemical substructure, 16 are count features, such as the number of bonds or the number of bromine atoms, and 4 are continuous features, such as molecular
weight or surface area. The response is in the column "Solubility" (the last column).

## Import the data

```{r}
# Import the train data
train = read_csv("./data/solubility_train.csv")
# Import the test data
test = read_csv("./data/solubility_test.csv")
```

## Set random seed

```{r}
set.seed(2020)
```


## Answer of the questions

#### a.Fit a linear model using least squares on the training data and calculate the mean square error using the test data

##### (1) Fit a linear model using least squares on the training data

```{r}
lm_fit = lm(train$Solubility ~ ., data = train)

# summary(lm_fit)
# There are too many predicators so I do not show the result

par(mfrow = c(2,2))

plot(lm_fit)
```

##### (2) Calculate the mean square error using the test data

```{r}
train_mse = mean(lm_fit$residuals^2)
train_mse
test_mse = mean((test$Solubility - predict(lm_fit, test)) ^ 2)
test_mse
```

The mean square error using the test data is 0.5558898.

#### b. Fit a ridge regression model on the training data, with lambda chosen by cross-validation. Report the test error.

##### (1) Fit a ridge regression model on the training data, with lambda chosen by cross-validation

```{r}
train_X = model.matrix(Solubility~.,train)[,-1]
train_Y = train$Solubility
train_control = trainControl(method = "cv",number = 10)
ridge_fit = train(
    x = train_X,
    y = train_Y, 
    method = 'glmnet',
    tuneGrid = expand.grid(alpha = 0,lambda = exp(seq(-8, 10, length = 100))),
    trControl = train_control,
    metric = 'RMSE'
)
```

```{r}
ridge_fit$bestTune
plot(ridge_fit, xTrans = function(x)log(x))
# coef(ridge_fit$finalModel, ridge_fit$bestTune$lambda)
# No variable is dropped from the ridge model, however parameters all become smaller.
```

##### (2) Report the test error

```{r}
test_X = model.matrix(Solubility~.,test)[,-1]
test_Y = test$Solubility
ridge_predict_Y = predict.train(ridge_fit, test_X)
ridge_test_mse = mean((test_Y - ridge_predict_Y)^2)

ridge_test_mse
```

The chosen $lambda$ is 0.1128362. The mean square error using the test data is 0.5134603.

#### c. Fit a lasso regression model on the training data, with lambda chosen by cross-validation. Report the test error, along with the number of non-zero coefficient estimates.

##### (1) Fit a lasso regression model on the training data, with lambda chosen by cross-validation

```{r}
lasso_fit = train(
    x = train_X,
    y = train_Y, 
    method = 'glmnet',
    tuneGrid = expand.grid(alpha = 1,lambda = exp(seq(-8, 10, length = 100))),
    trControl = train_control
)
```

```{r}
lasso_fit$bestTune
plot(lasso_fit, xTrans = function(x)log(x))
```

##### (2) Report the test error, along with the number of non-zero coefficient estimates
```{r}
lasso_predict_Y = predict.train(lasso_fit, test_X)
lasso_test_mse = mean((test_Y - lasso_predict_Y)^2)

lasso_test_mse

coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda) 
```

The chosen $lambda$ is 0.00427682. The mean square error using the test data is 0.5005751.
The number of non-zero coefficient estimates (exclude intercept) is 147.

#### d. Fit a principle component regression model on the training data, with M chosen by cross-validation. Report the test error, along with the value of M selected by cross-validation.

##### (1) Fit a pcr model on the training data, with M chosen by cross-validation

```{r}
train_X = model.matrix(Solubility~.,train)[,-1]
train_Y = train$Solubility
train_control = trainControl(method = "cv",number = 10)
pcr_fit = train(
    x = train_X,
    y = train_Y, 
    method = 'pcr',
    tuneLength = length(train) - 1,
    trControl = train_control,
    scale = TRUE
)
```

```{r}
plot(pcr_fit)
```

##### (2) Report the test error, along with the value of M selected by cross-validation

```{r}
pcr_predict_Y = predict.train(pcr_fit, test_X)
pcr_test_mse = mean((test_Y - pcr_predict_Y)^2)

pcr_test_mse

pcr_fit$bestTune
```

The value of M selected by cross-validation is 178. The mean square error using the test data is 0.5264698.

#### e. Briefly discuss the results obtained in a~d

```{r}
mse_table = tibble(
    metric = 'Test MSE',
    linear_model =  0.5558898,
    ridege = 0.5134603,
    lasso = 0.5005751,
    pcr = 0.5264698 
)
mse_table %>% knitr::kable(digits = 4)
```

By comparing the test mean square errors, we can see that the linear regression model performs worst and the principle component regression model also performs badly in the test data. The lasso model performs best. The ridge model performs better than the principle component regression model, but worse than the lasso model.   

Linear Regression Model: It keeps all variables without any constrain in the model and when some variables are corrlated there is a high variance problem.

Principal Componet Regression: Use a small number of linear combinations of the original inputs.

Ridge Model: Shrink and keep all variables .

Lasso Model: Shrink some variables to 0.(Can be used to do features selection)

#### f. Which model will you choose for predicting solubility?

I will choose the lasso model which performs best for predicting solubility.







